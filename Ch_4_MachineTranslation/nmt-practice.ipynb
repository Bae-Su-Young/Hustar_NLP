{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator, interleave_keys\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Example\n",
    "from mosestokenizer import *\n",
    "import torch\n",
    "\n",
    "from typing import Tuple\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### torchtext #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<s>'    # Start symbol\n",
    "EOS = '</s>'   # End symbol\n",
    "PAD = '<pad>'  # padding symbol\n",
    "\n",
    "# ex) 'I am a boy.' -> ['I', 'am', 'a', 'boy']\n",
    "tok_en = MosesTokenizer('en')#english\n",
    "tok_fr = MosesTokenizer('fr')#francef\n",
    "\n",
    "# Field: Tensor로 표현할 데이터의 타입, 처리 프로세스 등을 정의하는 객체\n",
    "#src : 변역할 입력문장\n",
    "src = Field(sequential=True,#sequntial쓰느냐...\n",
    "            use_vocab=True,#사전 쓰느냐...\n",
    "            pad_token=PAD,\n",
    "            tokenize=tok_en,\n",
    "            lower=True,\n",
    "            batch_first=True) # if=True shape:[Batch, length] else shape=[length, Batch] 첫번째 필드 크기를...\n",
    "\n",
    "#tgt: 번역된 문장....?\n",
    "tgt = Field(sequential=True,\n",
    "            use_vocab=True,\n",
    "            pad_token=PAD,\n",
    "            tokenize=tok_fr,\n",
    "            lower=True,\n",
    "            init_token=BOS,#Decorder는 LM유사하므로\n",
    "            eos_token=EOS,\n",
    "            batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_f = 'data/data' # 데이터 경로 (확장자 제외)\n",
    "\n",
    "# parallel data 각각 (en, de) 을 src Field 와 tgt Field에 정의된 형태로 처리.\n",
    "parallel_dataset = TranslationDataset(path=prefix_f, exts=('.en', '.fr'), \n",
    "                                      fields=[('src', src), ('tgt', tgt)])\n",
    "\n",
    "#parallel data: 원문-번역문 쌍인 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.datasets.translation.TranslationDataset object at 0x7f9b20bbfbe0>\n",
      "dict_items([('src', ['you', 'were', 'in', 'a', 'coma', '.']), ('tgt', ['tu', 'étais', 'dans', 'le', 'coma', '.'])])\n"
     ]
    }
   ],
   "source": [
    "print(parallel_dataset) \n",
    "\n",
    "print(parallel_dataset.examples[22222].__dict__.items()) # src 및 tgt 에 대한 samples 를 포함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'were', 'in', 'a', 'coma', '.']\n"
     ]
    }
   ],
   "source": [
    "print(parallel_dataset.examples[22222].src) # src 출력 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tu', 'étais', 'dans', 'le', 'coma', '.']\n"
     ]
    }
   ],
   "source": [
    "print(parallel_dataset.examples[22222].tgt) # tgt 출력 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 사전 구축 ########\n",
    "# src, tgt 필드에 사전 구축\n",
    "src.build_vocab(parallel_dataset, max_size=15000)\n",
    "tgt.build_vocab(parallel_dataset, max_size=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['freqs', 'itos', 'unk_index', 'stoi', 'vectors'])\n",
      "\n",
      "     <unk> |   0\n",
      "     <pad> |   1\n",
      "         . |   2\n",
      "         i |   3\n",
      "       you |   4\n",
      "        to |   5\n",
      "       the |   6\n",
      "         ? |   7\n",
      "         a |   8\n",
      "   &apos;t |   9\n",
      "        is |  10\n",
      "        it |  11\n",
      "        he |  12\n",
      "      that |  13\n",
      "   &apos;s |  14\n",
      "        of |  15\n"
     ]
    }
   ],
   "source": [
    "# 사전 내용 \n",
    "print(src.vocab.__dict__.keys())\n",
    "print('')\n",
    "# stoi: string to index 의 약자 == word2idx --> word2idx['posco'] -> 3 \n",
    "# itos: index to string 의 약자 == idx2word --> idx2word[3] -> 'posco'\n",
    "for i, (k, v) in enumerate(src.vocab.stoi.items()):\n",
    "    print ('{:>10s} | {:>3d}'.format(k, v))\n",
    "    if i == 15 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     <unk> |   0\n",
      "     <pad> |   1\n",
      "       <s> |   2\n",
      "      </s> |   3\n",
      "         . |   4\n",
      "        je |   5\n",
      "        de |   6\n",
      "       @-@ |   7\n",
      "         ? |   8\n",
      "       pas |   9\n",
      "      vous |  10\n",
      "       est |  11\n",
      "        il |  12\n",
      "       que |  13\n",
      "         à |  14\n",
      "        ne |  15\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(tgt.vocab.stoi.items()):\n",
    "    print ('{:>10s} | {:>3d}'.format(k, v))\n",
    "    if i == 15 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = parallel_dataset.split(split_ratio=0.95) # 0.95 = train / 0.05 = valid 데이터로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch iterator 생성.\n",
    "# iterator 를 반복하며 batch (src, tgt) 가 생성 됨.\n",
    "BATCH_SIZE = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Batch Iterator를 라이브러리로 만드는 것\n",
    "train_iterator, valid_iterator = BucketIterator.splits((train, valid), batch_size=BATCH_SIZE,\n",
    "                                                    sort_key=lambda x: interleave_keys(len(x.src), len(x.tgt)),\n",
    "                                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator 는 Batch 객체 (Tensor) 를 출력해주며, \n",
    "# Batch.src / Batch.tgt 로 parallel data각각에 대해 접근가능.\n",
    "\n",
    "# 예시.\n",
    "Batch = next(iter(train_iterator)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   4,   36,   66,   38,   31,  169,    2],\n",
       "        [  30,   14,    8, 1178,  370,    2,    1],\n",
       "        [  10,   11,   93,   43,  175,    7,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# src 에 저장된 데이터 출력\n",
    "# Field에 정의된 형식으로 데이터 전처리 (indexing 포함.)\n",
    "# 가장 긴 문장을 기준으로, 그 보다 짧은 문장은 Padding idx(=1) 을 부여.\n",
    "Batch.src "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,   10,   59,  480,  121,   72,  157,    4,    3],\n",
       "        [   2,   38,   11,   31, 1533,  252,    4,    3,    1],\n",
       "        [   2,   49,   11,   97,  372,    8,    3,    1,    1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Field에 정의된 형식으로 데이터 전처리 (indexing + bos + eos + pad 토큰 처리 됨.)\n",
    "Batch.tgt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoder 정의.\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, src_ntoken: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        self.src_ntoken = src_ntoken\n",
    "\n",
    "        self.embedding = nn.Embedding(src_ntoken, hidden_dim, padding_idx=src.vocab.stoi['<pad>'])\n",
    "\n",
    "        # batch_first = [B, L, dim]\n",
    "                        #  입력 차원  ,   출력차원\n",
    "        self.rnn = nn.GRU(hidden_dim, hidden_dim , bidirectional = True, batch_first=True) \n",
    "        \n",
    "        # bidirectional hidden을 하나의 hidden size로 mapping해주기 위한 Linear\n",
    "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = (Batch, Length) Tensor\n",
    "        embedded = self.dropout(self.embedding(src)) \n",
    "        # shape = (Batch, Length, hidden_dim)\n",
    "\n",
    "        # outputs: [B, L, D*2], hidden: [2, B, D] -> [1, B, D] + [1, B, D]\n",
    "        # Note: Bidirection=False 인 경우:  outputs: [B, L, D], hidden: [1, B, D]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "\n",
    "        # bidirection Dim(x2)을 projection --> [B, D]\n",
    "        last_hidden = self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)) \n",
    "        \n",
    "        # last bidirectional hidden (=Decoder init hidden) --> [1, B, D]\n",
    "        hidden = torch.tanh(last_hidden).unsqueeze(0) \n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Attention 모듈 정의 ###\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 attn_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        attn_in = (enc_hid_dim * 2) + dec_hid_dim # bidirectional hidden + dec_hidden\n",
    "        self.linear = nn.Linear(attn_in, attn_dim)\n",
    "        self.merge = nn.Linear(attn_dim, 1)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hiden = (Batch, 1, Dim) 길이가 1씩 들어오기 때문.\n",
    "        src_len = encoder_outputs.shape[1] \n",
    "        repeated_decoder_hidden = decoder_hidden.repeat(1, src_len, 1) # [B, src_len, D] -> 각각의 src단어와 연산해주기 위해 늘려준 결과.\n",
    "\n",
    "        # enc의 각 step의 hidden + decoder의 hidden 의 결과값 # [B, src_len, D*2] --> [B, src_len, D]\n",
    "        # tanh(W*h_dec  + U*h_enc) 수식 부분.\n",
    "        energy = torch.tanh(\n",
    "                    self.linear(\n",
    "                        torch.cat((repeated_decoder_hidden,encoder_outputs),dim=2)\n",
    "                    )\n",
    "        )# practice \n",
    "        score = self.merge(energy).squeeze(-1) # [B, src_len] 각 src 단어에 대한 점수 -> V^T tanh(W*h_dec  + U*h_enc) 부분\n",
    "        normalized_score = F.softmax(score, dim=1)  # softmax를 통해 확률분포값으로 변환\n",
    "        return  normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decoder 모듈 정의 ####\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, dec_ntoken: int, dropout: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim # Decoder RNN의 previous hidden\n",
    "        self.dropout = dropout\n",
    "        self.attention = Attention(enc_hid_dim=hidden_dim, \n",
    "                                   dec_hid_dim=hidden_dim, \n",
    "                                   attn_dim=hidden_dim) # attention layer\n",
    "        \n",
    "        self.dec_ntoken = dec_ntoken # tgt vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(dec_ntoken, hidden_dim, \n",
    "                                      padding_idx=tgt.vocab.stoi['<pad>'])\n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_dim, hidden_dim, batch_first=True) # bidirectinal=False 임.\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(self.hidden_dim*3, dec_ntoken) # Vocab 크기로 linear projection\n",
    "        self.sm = nn.LogSoftmax(dim=-1) # 확률 분포 값.\n",
    "\n",
    "    def _context_rep(self, dec_out, enc_outs):\n",
    "        scores = self.attention(dec_out, enc_outs) # score = [B, src_len]\n",
    "        scores = scores.unsqueeze(1) # [B, 1, src_len] -> weight value (softmax)\n",
    "\n",
    "        # scores: (batch, 1, src_len),  ecn_outs: (Batch, src_len, dim)\n",
    "        context_vector = torch.bmm(scores, enc_outs) # weighted average -> (batch, 1, dec_dim): encoder의 각 hidden의 weighted sum\n",
    "        return context_vector\n",
    "\n",
    "    def forward(self, input, decoder_hidden, encoder_outputs):\n",
    "        #인코더의 마지막 hidden=decoder_input\n",
    "        dec_outs = []\n",
    "        embedded = self.dropout(self.embedding(input)) # (Batch, length, Dim)\n",
    "        \n",
    "        # (Batch, 1, dim)  (batch, 1, dim) , ....,\n",
    "        for emb_t in embedded.split(1, dim=1): # Batch 별 각 단어 (=각 time step) 에 대한 embedding 출력 \n",
    "            rnn_out, decoder_hidden = self.rnn(emb_t, decoder_hidden) # feed input with previous decoder hidden at each step\n",
    "\n",
    "            context = self._context_rep(rnn_out, encoder_outputs) # C_t vector\n",
    "            rnn_context = self.dropout(torch.cat([rnn_out, context], dim=2)) \n",
    "            dec_out = self.linear(rnn_context) # W(H + C) \n",
    "            dec_outs += [self.sm(dec_out)]\n",
    "        \n",
    "        if len(dec_outs) > 1:\n",
    "            dec_outs = dec_outs[:-1] # trg = trg[:-1] # <E> 는 Decoder 입력으로 고려하지 않음.\n",
    "            dec_outs = torch.cat(dec_outs, dim=1) # convert list into tensor : [B, L, vocab]\n",
    "\n",
    "        else: # step-wise 로 decoding 하는 경우,\n",
    "            dec_outs = dec_outs[0] # [B=1, L=1, vocab]\n",
    "\n",
    "        return dec_outs, decoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seq-to-Seq 모델 정의 ###\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder: nn.Module,\n",
    "                 decoder: nn.Module,\n",
    "                 device: torch.device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        encoder_outputs, hidden = self.encoder(src) # encoder_outputs = (Batch, length, Dim * 2) , hidden = (Batch, Dim)\n",
    "        dec_out, _ = self.decoder(trg, hidden, encoder_outputs)\n",
    "        return dec_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(src.vocab)  # src 사전 크기\n",
    "OUTPUT_DIM = len(tgt.vocab) # tgt 사전 크기\n",
    "HID_DIM = 128 # rnn, embedding, 등. 모든 hidden 크기를 해당 값으로 통일함. (실습의 용이성을 위함.)\n",
    "D_OUT = 0.1 # Dropout  확률\n",
    "BATCH_SIZE = 26\n",
    "\n",
    "train_iterator, valid_iterator = BucketIterator.splits((train, valid), batch_size=BATCH_SIZE,\n",
    "                                                    sort_key=lambda x: interleave_keys(len(x.src), len(x.tgt)),\n",
    "                                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 및 디코더 생성\n",
    "# Seq2Seq 모델 생성\n",
    "encoder = Encoder(HID_DIM, INPUT_DIM, D_OUT)\n",
    "decoder = Decoder(HID_DIM, OUTPUT_DIM, D_OUT)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "\n",
    "model.apply(init_weights) # 모델 파라미터 초기화\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005) # Optimizer 설정\n",
    "criterion = nn.NLLLoss(ignore_index=tgt.vocab.stoi['<pad>'], reduction='mean') # LOSS 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(13296, 128, padding_idx=1)\n",
      "    (rnn): GRU(128, 128, batch_first=True, bidirectional=True)\n",
      "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): Attention(\n",
      "      (linear): Linear(in_features=384, out_features=128, bias=True)\n",
      "      (merge): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "    (embedding): Embedding(15004, 128, padding_idx=1)\n",
      "    (rnn): GRU(128, 128, batch_first=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=384, out_features=15004, bias=True)\n",
      "    (sm): LogSoftmax(dim=-1)\n",
      "  )\n",
      ")\n",
      "The model has 9,778,461 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# 모델 정보 및 파라미터 수 출력\n",
    "def count_parameters(model: nn.Module):\n",
    "    print(model)\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 학습 함수 ###\n",
    "def train(model, iterator, optimize, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        tgt = batch.tgt\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, tgt) # [batch, length, vocab_size]\n",
    "        output = output.view(-1, output.size(-1)) # flatten --> (batch * length, vocab_size)\n",
    "\n",
    "        tgt = tgt.unsqueeze(-1)[:,1:,:].squeeze(-1).contiguous() # 정답에는 <S>가 포함되지 않음으로, 이를 삭제\n",
    "        tgt = tgt.view(-1) # flatten = (batch * length)\n",
    "\n",
    "        loss = criterion(output, tgt) # tgt 이 내부적으로 one_hot으로 변환됨 --> (batch * length, vocab_size)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if(((i+1) % int(len(iterator)*0.2)) == 0):\n",
    "            num_complete = batch.batch_size * (i+1)\n",
    "            total_size = batch.batch_size * int(len(iterator))\n",
    "            ratio = num_complete/total_size * 100\n",
    "            print('| Current Epoch:  {:>4d} / {:<5d} ({:2d}%) | Train Loss: {:3.3f}'.\n",
    "                  format(num_complete, batch.batch_size * int(len(iterator)), round(ratio), loss.item())\n",
    "                  )\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 평가 함수 ###\n",
    "def evaluate(model: nn.Module, iterator: BucketIterator,\n",
    "             criterion: nn.Module):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(iterator):\n",
    "            src = batch.src\n",
    "            tgt = batch.tgt\n",
    "\n",
    "            output = model(src, tgt)\n",
    "            output = output.view(-1, output.size(-1)) # flatten (batch * length, vocab_size)\n",
    "\n",
    "            tgt = tgt.unsqueeze(-1)[:,1:,:].squeeze(-1).contiguous() # remove <S> placed at first from targets\n",
    "            tgt = tgt.view(-1) # flatten target with shape = (batch * length)\n",
    "            loss = criterion(output, tgt)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시간 카운트를 위한 함수 #\n",
    "def epoch_time(start_time: int, end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'function' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11495/489080041.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11495/956385411.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimize, criterion, clip)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/course/lib/python3.8/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/course/lib/python3.8/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36minit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state_this_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restored_from_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/course/lib/python3.8/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m                                  self.batch_size_fn)\n\u001b[1;32m    247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             self.batches = pool(self.data(), self.batch_size,\n\u001b[0m\u001b[1;32m    249\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                                 \u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/course/lib/python3.8/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'function' has no len()"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 15 # 최대 epoch 크기\n",
    "CLIP = 0.2 # weight cliping \n",
    "isTrain = True # True 인 경우 아래 학습 코드 실행, False인 경우 저장된 model 로드만 수행.\n",
    "\n",
    "if isTrain:\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "        valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        print('='*65)\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "        print('='*65)\n",
    "\n",
    "    with open('NMT.pt', 'wb') as f:\n",
    "        print(\"model saving..\")\n",
    "        torch.save(model, f)\n",
    "\n",
    "else:\n",
    "    with open('NMT.pt', 'rb') as f:\n",
    "        model = torch.load(f).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Greedy decoding \n",
    "def greedy_decoding(model, input, fields, maxLen=20):\n",
    "    src_field = [('src', fields[0])]\n",
    "    tgt_field = fields[1]\n",
    "\n",
    "    ex = Example.fromlist([input], src_field) # field에 정의된 내용으로 전처리 (tokenizing) 수행\n",
    "    src_tensor = src.numericalize([ex.src], device) # torch.Tensor로 치환, indexing, bos, eos 등의 처리과정도 함께 적용됨.\n",
    "    tgt_tensor = torch.tensor([[tgt_field.vocab.stoi['<s>']]], device=device) # Decoder 초기 입력 \n",
    "    model.eval()\n",
    "\n",
    "    dec_result = []\n",
    "    with torch.no_grad():\n",
    "        enc_out, hidden = model.encoder(src_tensor)\n",
    "        for i in range(maxLen):\n",
    "            # Step1: tgt_tensor (입력) 과 인코더의 출력을 이용하여 디코더 결과 출력\n",
    "            dec_out,dec_hidden=model.decoder(tgt_tensor,hidden,enc_output)\n",
    "            \n",
    "            # Do someting about Step1 here..\n",
    "            # ex) dec_step, hidden = model.decoder(....)\n",
    "\n",
    "            # Step2: 디코더의 출력결과 (확룰분포) 에서 Top1 에 해당하는 word Index 추출\n",
    "            val,idx=torch.topk(enc_out,1)\n",
    "            \n",
    "            # Do someting about Step2 here..\n",
    "            # ex) use torch.topk(..) \n",
    "            \n",
    "            # Step3: \n",
    "            # if: 출력된 word Index == EOS 인 경우 디코딩 중지 (break).\n",
    "            if tgt_field.vocab.itos[idx] == '</S>':\n",
    "                break\n",
    "            else:\n",
    "                dec_result.append(idx.item())\n",
    "                tgt_tensor=top_idx.view(1,1)\n",
    "                \n",
    "    dec_result = [tgt_field.vocab.itos[w] for w in dec_result] # Word index를 단어로 치환\n",
    "    return dec_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy decoding 수행\n",
    "\n",
    "input_sent = input('Enter a english sentence:  ')\n",
    "output = greedy_decoding(model, input_sent, fields=(src, tgt))\n",
    "output = MosesDetokenizer('fr')(output)\n",
    "print('> ', input_sent)\n",
    "print('< ', output)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
