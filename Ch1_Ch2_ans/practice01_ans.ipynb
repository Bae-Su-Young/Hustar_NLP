{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    '나': 0,\n",
    "    '는': 1,\n",
    "    '김밥': 2,\n",
    "    '과': 3,\n",
    "    '라면': 4,\n",
    "    '이': 5,\n",
    "    '좋다': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(7, 10)\n",
      "Parameter containing:\n",
      "tensor([[-0.1693, -0.3529,  1.0629,  0.1398, -0.1607,  0.1683,  0.6768, -2.5792,\n",
      "          0.5665, -0.5511],\n",
      "        [-0.3787, -0.2830,  1.1567, -1.0070, -0.5515,  1.9946, -2.5155,  0.0406,\n",
      "          0.0478, -0.7321],\n",
      "        [ 0.6929, -0.8344, -0.2919, -0.1401,  1.0639, -0.1878, -0.6071, -2.3223,\n",
      "         -1.0445, -0.3781],\n",
      "        [-2.8893, -0.7158,  0.2928, -0.3654, -1.1717,  0.2758, -0.5463, -0.2353,\n",
      "         -1.1753,  0.7306],\n",
      "        [ 0.5907, -2.2213,  0.4761,  0.3602,  0.3796, -0.7976,  1.5590, -1.1483,\n",
      "          0.9510,  1.2343],\n",
      "        [-0.4532,  0.4466,  0.4170,  0.3523, -0.2217, -0.8274,  0.7790, -0.9496,\n",
      "         -1.5910,  0.4920],\n",
      "        [ 0.2023,  0.8373, -1.4675, -0.8615, -0.1627, -0.0912, -0.7329,  0.6762,\n",
      "         -0.0879,  0.3074]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "dim=10\n",
    "emb_mtx = torch.nn.Embedding(len(vocab), dim)\n",
    "\n",
    "print(emb_mtx)\n",
    "print(emb_mtx.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([4])\n",
      "Shape: torch.Size([1])\n",
      "\n",
      "Tensor:\n",
      "tensor([[ 0.5907, -2.2213,  0.4761,  0.3602,  0.3796, -0.7976,  1.5590, -1.1483,\n",
      "          0.9510,  1.2343]], grad_fn=<EmbeddingBackward>)\n",
      "Shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "## Practice 1 ##\n",
    "\n",
    "# print word embedding of '라면'\n",
    "idx = torch.tensor([vocab['라면']],dtype=torch.long)\n",
    "print(\"Tensor: {}\\nShape: {}\\n\".format(idx, idx.size()))\n",
    "\n",
    "emb = emb_mtx(idx) # make word embedding for '라면'\n",
    "print(\"Tensor:\\n{}\\nShape: {}\".format(emb, emb.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([2, 4, 6])\n",
      "Shape: torch.Size([3])\n",
      "\n",
      "Tensor:\n",
      "tensor([[ 0.6929, -0.8344, -0.2919, -0.1401,  1.0639, -0.1878, -0.6071, -2.3223,\n",
      "         -1.0445, -0.3781],\n",
      "        [ 0.5907, -2.2213,  0.4761,  0.3602,  0.3796, -0.7976,  1.5590, -1.1483,\n",
      "          0.9510,  1.2343],\n",
      "        [ 0.2023,  0.8373, -1.4675, -0.8615, -0.1627, -0.0912, -0.7329,  0.6762,\n",
      "         -0.0879,  0.3074]], grad_fn=<EmbeddingBackward>)\n",
      "Shape: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "## Practice 2 ##\n",
    "\n",
    "# print word embeddings for a given sentence: \"김밥 라면 좋다\"\n",
    "sent = ['김밥', '라면', '좋다']\n",
    "idxs = []\n",
    "for word in sent:\n",
    "    idx = vocab[word]\n",
    "    idxs.append(idx) # append idx to idxs\n",
    "\n",
    "idxs = torch.tensor(idxs,dtype=torch.long)\n",
    "print(\"Tensor: {}\\nShape: {}\\n\".format(idxs, idxs.size()))\n",
    "\n",
    "emb = emb_mtx(idxs)\n",
    "print(\"Tensor:\\n{}\\nShape: {}\".format(emb, emb.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[2, 4, 6],\n",
      "        [0, 1, 4]])\n",
      "Shape: torch.Size([2, 3])\n",
      "\n",
      "Tensor:\n",
      "tensor([[[ 0.6929, -0.8344, -0.2919, -0.1401,  1.0639, -0.1878, -0.6071,\n",
      "          -2.3223, -1.0445, -0.3781],\n",
      "         [ 0.5907, -2.2213,  0.4761,  0.3602,  0.3796, -0.7976,  1.5590,\n",
      "          -1.1483,  0.9510,  1.2343],\n",
      "         [ 0.2023,  0.8373, -1.4675, -0.8615, -0.1627, -0.0912, -0.7329,\n",
      "           0.6762, -0.0879,  0.3074]],\n",
      "\n",
      "        [[-0.1693, -0.3529,  1.0629,  0.1398, -0.1607,  0.1683,  0.6768,\n",
      "          -2.5792,  0.5665, -0.5511],\n",
      "         [-0.3787, -0.2830,  1.1567, -1.0070, -0.5515,  1.9946, -2.5155,\n",
      "           0.0406,  0.0478, -0.7321],\n",
      "         [ 0.5907, -2.2213,  0.4761,  0.3602,  0.3796, -0.7976,  1.5590,\n",
      "          -1.1483,  0.9510,  1.2343]]], grad_fn=<EmbeddingBackward>)\n",
      "Shape: torch.Size([2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "## Practice 03 ##\n",
    "# construct batch level word embeddings: [\"김밥 라면 좋다\", \"나 는 라면\"]\n",
    "\n",
    "sents = [['김밥', '라면', '좋다'],\n",
    "         ['나', '는', '라면']]\n",
    "\n",
    "batch_idxs = []\n",
    "for sent in sents:\n",
    "    idxs = []\n",
    "    for word in sent:\n",
    "        idx = vocab[word]\n",
    "        idxs.append(idx)\n",
    "    batch_idxs.append(idxs)\n",
    "\n",
    "batch_idxs = torch.tensor(batch_idxs,dtype=torch.long)\n",
    "print(\"Tensor:\\n{}\\nShape: {}\".format(batch_idxs, batch_idxs.size()))\n",
    "print('')\n",
    "\n",
    "emb = emb_mtx(batch_idxs)\n",
    "print(\"Tensor:\\n{}\\nShape: {}\".format(emb, emb.size()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
